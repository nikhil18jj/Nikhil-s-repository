credit=read.csv("C:/Users/nikhi/Desktop/Credit_Rev-1.csv",header=TRUE)
plot(credit$balance,credit$income,type="p",col="skyblue",xlab="Balance",ylab="Income",main="Balance vs Income")
plot(credit$Age,credit$income,type="p",col="skyblue",xlab="Balance",ylab="Age",main="Balance vs Age")
cor(credit$balance,credit$income)
#Simple logistic regression
glm.fit=glm(default~.,family=binomial,data=credit)
#Default vs student,balance,age,income
#family=binomial to ensure logistic regression is used

print(glm.fit)
#Diagnosing model
summary(glm.fit,correlation=TRUE,symbolic.cor=TRUE)
#Null dispersion
#correlation:logical; if TRUE, the correlation matrix of the estimated parameters is returned and printed.
#symbolic.cor the correlations in a symbolic form (see symnum) rather than as numbers.
#the matrix of coefficients, standard errors, z-values and p-values.
#If a 95% confidence interval is available for an absolute measure of intervention effect (e.g. SMD, risk difference, rate difference), then the standard error can be calculated as

#SE = (upper limit - lower limit) / 3.92.

#For 90% confidence intervals divide by 3.29 rather than 3.92; for 99% confidence intervals divide by 5.15.



#Where exact P values are quoted alongside estimates of intervention effect, it is possible to estimate standard errors. While all tests of statistical significance produce P values, different tests use different mathematical approaches to obtain a P value. The method here assumes P values have been obtained through a particularly simple approach of dividing the effect estimate by its standard error and comparing the result (denoted Z) with a standard normal distribution (statisticians often refer to this as a Wald test). Where significance tests have used other mathematical approaches the estimated standard errors may not coincide exactly with the true standard errors.



#The first step is to obtain the Z value corresponding to the reported P value from a table of the standard normal distribution. A standard error may then be calculated as

#SE = intervention effect estimate / Z.
#The p-value is a probability.  it is the probability that the observed spatial pattern was created by some random process. When the p-value is very small, it means it is very unlikely (small probability)<0.05 that the observed spatial pattern is the result of random processes, so you can reject the null hypothesis.
#Z-scores are standard deviations. If, for example, a tool returns a z-score of +2.5, you would say that the result is 2.5 standard deviations

glm.fit$coefficients
plot(glm.fit)

#Confidence interval
confint(glm.fit)
#Multi logistic regression
#Null dispersion
#correlation:logical; if TRUE, the correlation matrix of the estimated parameters is returned and printed.
#symbolic.cor the correlations in a symbolic form (see symnum) rather than as numbers.
#the matrix of coefficients, standard errors, z-values and p-values.
glm.fit1=glm(default~student+balance+Age+income,family=binomial,data=credit)
print(glm.fit1)
summary(glm.fit1,correlation=TRUE,symbolic.cor=TRUE)
glm.fit1$coefficients
plot(glm.fit1)
#Confidence interval
confint(glm.fit1)

X=c(401,402,403,404,405,406)
default=""[-1]
student=c("No","Yes","Yes","No","No","No")
balance=c(1500,1000,2000,2500,1600,1900)
Age=c(34,82,71,36,68,77)
income=c(10000,18000,21000,37000,40000,24000)
newx=c(X,default,student,balance,Age,income)
new=as.data.frame(newx)
pred1=predict(glm.fit,new,type="response")
pred1
pred2=predict(glm.fit1,new,type="response")
pred2
#Probabilities of students defaulting
#Based on the model,students 3,4,5,6 may default while 1,2 will not default

